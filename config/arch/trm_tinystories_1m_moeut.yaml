name: recursive_reasoning.trm@TinyRecursiveReasoningModel_ACTV1
loss:
  name: losses@ACTLossHead
  loss_type: softmax_cross_entropy

halt_exploration_prob: 0.0
halt_max_steps: 1

# Match existing pattern: 2 L_layers, 0 H_layers, repeated via H_cycles
# Using L_cycles=4 (4x sparsity compensation for MoEUT)
# H_cycles=1, L_cycles=4, L_layers=2 â†’ 1*4*2 = 8 effective passes
H_cycles: 1
L_cycles: 7

H_layers: 0
L_layers: 2

# Match MoEUT_TinyStories_1M
hidden_size: 64
num_heads: 1

expansion: 1  # Not used when use_moeut=True

puzzle_emb_ndim: 0

pos_encodings: rope
forward_dtype: float32

mlp_t: False
puzzle_emb_len: 0
no_ACT_continue: True
tie_word_embeddings: True

# MoEUT config matching MoEUT_TinyStories_1M
use_moeut: True

# FFN: 8 experts * 192 size, k=2 active (scaled up for ~426k params)
moe_ff_n_experts: 8
moe_ff_expert_size: 192
moe_ff_k: 2

# Attention: 2 experts, k=1 active
moe_att_n_experts: 2
moe_att_k: 1

# Regularization
moe_expert_dropout: 0.0
#moe_entropy_reg: 0.01
#moe_att_entropy_reg: 0.001

# Load balancing: use loss-free bias balancing (DeepSeek approach) instead of auxiliary loss
moe_balance_coef: 0.0  # Disable loss-based balancing
moe_bias_balancing: True  # Enable loss-free bias balancing
moe_bias_update_rate: 0.001
moe_bias_momentum: 0.9  # EMA for running expert load
moe_bias_clip: 1.0  # Clamp DeepSeek-style routing bias magnitude
